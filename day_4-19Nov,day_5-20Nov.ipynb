{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satyamnewale/numpy-Book/blob/main/day_4-19Nov%2Cday_5-20Nov.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1_MiHXxVyuL"
      },
      "outputs": [],
      "source": [
        "day4_19Nov"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK_07s_JVx3o"
      },
      "source": [
        "axis = 0 VS axis = 1 on shape (n_sampke, n_features)\n",
        "---\n",
        "Axis meaning on (n_samples, n_features)\n",
        "\n",
        "\n",
        "1. In ML, a typical dataset matrix\n",
        "X has shape\n",
        "(n\n",
        "samples\n",
        " ,n\n",
        "features\n",
        " ), meaning each row is one sample and each column is one feature.​\n",
        "\n",
        "- Row = sample: features for one training example.​\n",
        "\n",
        "- Column = feature: same measurement across all samples.​\n",
        "\n",
        "2. NumPy’s axis parameter says which dimension you are collapsing over:\n",
        "\n",
        "- axis=0 → collapse down rows, compute per‑column / per‑feature statistics.​\n",
        "\n",
        "- axis=1 → collapse across columns, compute per‑row / per‑sample statistics.​\n",
        "\n",
        "3. For a 2D array X.shape == (n_samples, n_features):\n",
        "\n",
        "- X.sum(axis=0) → shape\n",
        "(\n",
        "n\n",
        "features\n",
        ",\n",
        ")\n",
        " one value per column/feature.​\n",
        "\n",
        "- X.sum(axis=1) → shape\n",
        "(\n",
        "n\n",
        "samples\n",
        ",\n",
        ") one value per row/sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owmIhqldVvKt",
        "outputId": "36441793-7a57-4625-ff4e-21cfedafd894"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "axis = none - sum of axis with none : 78, shape: () \n",
            "axis = none - mean of axis with none : 6.5, shape: () \n",
            "axis = none - min of axis with none : 1, shape: () \n",
            "axis = none - max of axis with none : 78, shape: () \n",
            "---------------------------------------------------------------------\n",
            "axis = 0 - sum of axis with 0 : [22 26 30], shape: (3,) \n",
            "axis = 0 - mean of axis with 0 : [5.5 6.5 7.5], shape: (3,) \n",
            "axis = 0 - min of axis with 0 : [1 2 3], shape: (3,) \n",
            "axis = 0 - max of axis with 0 : [22 26 30], shape: (3,) \n",
            "---------------------------------------------------------------------\n",
            "axis = 1 - sum of axis with 1 : [ 6 15 24 33], shape: (4,) \n",
            "axis = 1 - mean of axis with 1 : [ 2.  5.  8. 11.], shape: (4,) \n",
            "axis = 1 - min of axis with 1 : [ 1  4  7 10], shape: (4,) \n",
            "axis = 1 - max of axis with 1 : [ 6 15 24 33], shape: (4,) \n",
            "---------------------------------------------------------------------\n",
            "axis = 0 - sum of axis with 0 with dims: [[22 26 30]], shape: (1, 3) \n",
            "axis = 0 - mean of axis with 0 with dims: [[5.5 6.5 7.5]], shape: (1, 3) \n",
            "axis = 0 - min of axis with 0 with dims: [[1 2 3]], shape: (1, 3) \n",
            "axis = 0 - max of axis with 0 with dims: [[22 26 30]], shape: (1, 3) \n",
            "---------------------------------------------------------------------\n",
            "axis = 1 - sum of axis with 1 with dims: [[ 6]\n",
            " [15]\n",
            " [24]\n",
            " [33]], shape: (4, 1) \n",
            "axis = 1 - mean of axis with 1 with dims: [[ 2.]\n",
            " [ 5.]\n",
            " [ 8.]\n",
            " [11.]], shape: (4, 1) \n",
            "axis = 1 - min of axis with 1 with dims: [[ 1]\n",
            " [ 4]\n",
            " [ 7]\n",
            " [10]], shape: (4, 1) \n",
            "axis = 1 - max of axis with 1 with dims: [[ 6]\n",
            " [15]\n",
            " [24]\n",
            " [33]], shape: (4, 1) \n",
            "---------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.array([\n",
        "    [1, 2, 3],   # row 0\n",
        "    [4, 5, 6],   # row 1\n",
        "    [7, 8, 9],   # row 2\n",
        "    [10,11,12],  # row 3\n",
        "])  # shape (4,3)\n",
        "\n",
        "print(\"---------------------------------------------------------------------\")\n",
        "sum_axis_none = np.sum(X, axis=None, keepdims=False)\n",
        "mean_axis_none = np.mean(X, axis=None, keepdims=False)\n",
        "min_axis_none = np.min(X, axis=None, keepdims=False)\n",
        "max_axis_none = np.max(X, axis=None, keepdims=False)\n",
        "\n",
        "print(f\"axis = none - sum of axis with none : {sum_axis_none}, shape: {sum_axis_none.shape} \") # scalar shape\n",
        "print(f\"axis = none - mean of axis with none : {mean_axis_none}, shape: {mean_axis_none.shape} \") # scalar shape\n",
        "print(f\"axis = none - min of axis with none : {min_axis_none}, shape: {min_axis_none.shape} \") # scalar shape\n",
        "print(f\"axis = none - max of axis with none : {sum_axis_none}, shape: {max_axis_none.shape} \") # scalar shape\n",
        "\n",
        "print(\"---------------------------------------------------------------------\")\n",
        "# down the row - column wise - with no keepdims\n",
        "sum_axis_0 = np.sum(X, axis=0, keepdims=False)\n",
        "mean_axis_0 = np.mean(X, axis=0, keepdims=False)\n",
        "min_axis_0 = np.min(X, axis=0, keepdims=False)\n",
        "max_axis_0 = np.max(X, axis=0, keepdims=False)\n",
        "\n",
        "print(f\"axis = 0 - sum of axis with 0 : {sum_axis_0}, shape: {sum_axis_0.shape} \") # vector output\n",
        "print(f\"axis = 0 - mean of axis with 0 : {mean_axis_0}, shape: {mean_axis_0.shape} \") # vector output\n",
        "print(f\"axis = 0 - min of axis with 0 : {min_axis_0}, shape: {min_axis_0.shape} \") # vector output\n",
        "print(f\"axis = 0 - max of axis with 0 : {sum_axis_0}, shape: {max_axis_0.shape} \") # vector output\n",
        "\n",
        "print(\"---------------------------------------------------------------------\")\n",
        "#side the row - row wise - with no keepdims\n",
        "sum_axis_1 = np.sum(X, axis=1, keepdims=False)\n",
        "mean_axis_1 = np.mean(X, axis=1, keepdims=False)\n",
        "min_axis_1 = np.min(X,axis=1,keepdims=False)\n",
        "max_axis_1 = np.max(X, axis=1, keepdims=False)\n",
        "\n",
        "print(f\"axis = 1 - sum of axis with 1 : {sum_axis_1}, shape: {sum_axis_1.shape} \") # vector shape\n",
        "print(f\"axis = 1 - mean of axis with 1 : {mean_axis_1}, shape: {mean_axis_1.shape} \") # vector shape\n",
        "print(f\"axis = 1 - min of axis with 1 : {min_axis_1}, shape: {min_axis_1.shape} \") # vector shape\n",
        "print(f\"axis = 1 - max of axis with 1 : {sum_axis_1}, shape: {max_axis_1.shape} \") # vector shape\n",
        "\n",
        "print(\"---------------------------------------------------------------------\")\n",
        "# down the row - column wise - with keepdims\n",
        "sum_axis_0_dims = np.sum(X, axis=0, keepdims=True) #2D matrix as output\n",
        "mean_axis_0_dims = np.mean(X, axis=0, keepdims=True) #2D matrix as output\n",
        "min_axis_0_dims = np.min(X, axis=0, keepdims=True) #2D matrix as output\n",
        "max_axis_0_dims = np.max(X, axis=0, keepdims=True) #2D matrix as output\n",
        "\n",
        "print(f\"axis = 0 - sum of axis with 0 with dims: {sum_axis_0_dims}, shape: {sum_axis_0_dims.shape} \") # matrix output\n",
        "print(f\"axis = 0 - mean of axis with 0 with dims: {mean_axis_0_dims}, shape: {mean_axis_0_dims.shape} \") # matrix output\n",
        "print(f\"axis = 0 - min of axis with 0 with dims: {min_axis_0_dims}, shape: {min_axis_0_dims.shape} \") # matrix output\n",
        "print(f\"axis = 0 - max of axis with 0 with dims: {sum_axis_0_dims}, shape: {max_axis_0_dims.shape} \") # matrix output\n",
        "\n",
        "print(\"---------------------------------------------------------------------\")\n",
        "#side the row - row wise - with keepdims\n",
        "sum_axis_1_dims = np.sum(X, axis=1, keepdims=True) #2D matrix as output\n",
        "mean_axis_1_dims = np.mean(X, axis=1, keepdims=True) #2D matrix as output\n",
        "min_axis_1_dims = np.min(X,axis=1,keepdims=True) #2D matrix as output\n",
        "max_axis_1_dims = np.max(X, axis=1, keepdims=True) #2D matrix as output\n",
        "\n",
        "print(f\"axis = 1 - sum of axis with 1 with dims: {sum_axis_1_dims}, shape: {sum_axis_1_dims.shape} \") # matrix shape\n",
        "print(f\"axis = 1 - mean of axis with 1 with dims: {mean_axis_1_dims}, shape: {mean_axis_1_dims.shape} \") # matrix shape\n",
        "print(f\"axis = 1 - min of axis with 1 with dims: {min_axis_1_dims}, shape: {min_axis_1_dims.shape} \") # matrix shape\n",
        "print(f\"axis = 1 - max of axis with 1 with dims: {sum_axis_1_dims}, shape: {max_axis_1_dims.shape} \") # matrix shape\n",
        "\n",
        "print(\"---------------------------------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI6s6LtceQRl"
      },
      "source": [
        "1. What keepdims=True actually does\n",
        "- Formal definition: keepdims=True keeps reduced axes in the result as length‑1 dimensions, instead of removing them.\n",
        "\n",
        "2. Why keepdims matters for normalization\n",
        "In normalization, you usually:\n",
        "\n",
        "- Compute statistics (mean, std, or norm) over rows or columns.​\n",
        "\n",
        "- Subtract/divide those statistics from the original matrix X.​\n",
        "\n",
        "3. For broadcasting to work easily:\n",
        "\n",
        "- For row‑wise normalization (per sample): want stats of shape (n_samples, 1) so they stretch across features.​\n",
        "\n",
        "- For column‑wise normalization (per feature): want stats of shape (1, n_features) so they stretch down rows.​\n",
        "\n",
        "keepdims=True gives exactly these shapes directly.​\n",
        "\n",
        "Without keepdims, you’d get 1D shapes (n_samples,) or (n_features,), which sometimes broadcast as you want but sometimes cause confusion, especially when mixing with other operations or higher‑dimensional data.​\n",
        "\n",
        "Pitfall: omit keepdims and you get row_norms.shape == (n_samples,). This still broadcasts, but you lose the clear “column vector” geometry, and some later code expecting 2D may break.\n",
        "\n",
        "---\n",
        "Broadcasting row/column stats back to matrix\n",
        "---\n",
        "- Broadcasting rule (intuitive): if you try to operate on arrays with shapes that differ, NumPy will “stretch” dimensions of size 1 to match the other side, dimension by dimension from the end.​\n",
        "\n",
        "1. For a 2D X.shape == (n_samples, n_features):\n",
        "\n",
        "- If row_stats.shape == (n_samples, 1), then X - row_stats subtracts per row, same value across columns.​\n",
        "\n",
        "- If col_stats.shape == (1, n_features), then X - col_stats subtracts per column, same value across rows.​\n",
        "\n",
        "That’s exactly why keepdims=True is so nice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37W1K1XGZ1b8",
        "outputId": "66324c60-79d8-4171-ff4c-47300996a6fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "axis = 0 - mean of axis with 0 : [5.5 6.5 7.5], shape: (3,) \n",
            "axis = 1 - mean of axis with 1 : [ 2.  5.  8. 11.], shape: (4,) \n",
            "axis = 0 - mean of axis with 0 with dims: [[5.5 6.5 7.5]], shape: (1, 3) \n",
            "axis = 1 - mean of axis with 1 with dims: [[ 2.]\n",
            " [ 5.]\n",
            " [ 8.]\n",
            " [11.]], shape: (4, 1) \n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.array([\n",
        "    [1, 2, 3],   # row 0\n",
        "    [4, 5, 6],   # row 1\n",
        "    [7, 8, 9],   # row 2\n",
        "    [10,11,12],  # row 3\n",
        "])  # shape (4,3)\n",
        "\n",
        "mean_axis_0 = np.mean(X, axis=0, keepdims=False)\n",
        "mean_axis_1 = np.mean(X, axis=1, keepdims=False)\n",
        "mean_axis_0_dims = np.mean(X, axis=0, keepdims=True) #2D matrix as output\n",
        "mean_axis_1_dims = np.mean(X, axis=1, keepdims=True) #2D matrix as output\n",
        "\n",
        "print(f\"axis = 0 - mean of axis with 0 : {mean_axis_0}, shape: {mean_axis_0.shape} \") # vector output\n",
        "print(f\"axis = 1 - mean of axis with 1 : {mean_axis_1}, shape: {mean_axis_1.shape} \") # vector shape\n",
        "print(f\"axis = 0 - mean of axis with 0 with dims: {mean_axis_0_dims}, shape: {mean_axis_0_dims.shape} \") # matrix output\n",
        "print(f\"axis = 1 - mean of axis with 1 with dims: {mean_axis_1_dims}, shape: {mean_axis_1_dims.shape} \") # matrix shape\n",
        "\n",
        "#when keepdim is true the true shape is never loss even if the reduction happens it preserves its shape , whereas when kept false the shape will be reduced to 1D matrix (vector)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvieGnmFokwR",
        "outputId": "f6e5f312-124d-482f-96ba-1681c54f250c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "row normalisation order=2 ,axis=1 ,dimensions kept: [[ 9.16515139]\n",
            " [24.41311123]\n",
            " [40.24922359]], shape: (3, 1).\n",
            "row normalisation order=2 ,axis=1 ,dimensions not kept: [ 9.16515139 24.41311123 40.24922359], shape: (3,).\n",
            "col normalisation order=2 ,axis=1 ,dimensions kept: [[19.26136028 22.15851981 25.19920634 28.33725463]], shape: (1, 4).\n",
            "col normalisation order=2 ,axis=1 ,dimensions not kept: [19.26136028 22.15851981 25.19920634 28.33725463], shape: (4,).\n",
            "X/row_norms fails ((3,4)/(3,) != broadcasting):due to dimesin reduction and conversion of matrix to vector it became 1D vector. while broadcasting due to vector shape missmatch and rule violation it fails.\n",
            "norm_col: [[0.05191741 0.1353881  0.19841895 0.24702464]\n",
            " [0.46725672 0.49642305 0.51588926 0.5293385 ]\n",
            " [0.88259602 0.857458   0.83335958 0.81165237]], this works due to broadcasting rule was satisfied.\n",
            "[[0.10910895 0.32732684 0.54554473 0.76376262]\n",
            " [0.36865436 0.45057756 0.53250075 0.61442394]\n",
            " [0.4223684  0.4720588  0.52174919 0.57143959]] [[0.05191741 0.1353881  0.19841895 0.24702464]\n",
            " [0.46725672 0.49642305 0.51588926 0.5293385 ]\n",
            " [0.88259602 0.857458   0.83335958 0.81165237]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.arange(1,25,2).reshape(3,4)\n",
        "\n",
        "row_norms = np.linalg.norm(X, ord=2, axis=1, keepdims=False)\n",
        "row_norms_dims = np.linalg.norm(X, ord=2, axis=1, keepdims=True)\n",
        "\n",
        "col_norms = np.linalg.norm(X, ord=2, axis=0, keepdims=False)\n",
        "col_norms_dims = np.linalg.norm(X, ord=2, axis=0, keepdims=True)\n",
        "\n",
        "print(f\"row normalisation order=2 ,axis=1 ,dimensions kept: {row_norms_dims}, shape: {row_norms_dims.shape}.\")\n",
        "print(f\"row normalisation order=2 ,axis=1 ,dimensions not kept: {row_norms}, shape: {row_norms.shape}.\")\n",
        "\n",
        "print(f\"col normalisation order=2 ,axis=1 ,dimensions kept: {col_norms_dims}, shape: {col_norms_dims.shape}.\")\n",
        "print(f\"col normalisation order=2 ,axis=1 ,dimensions not kept: {col_norms}, shape: {col_norms.shape}.\")\n",
        "\n",
        "#when dimensions are not reduced ,broadcasting becomes difficult as few time broadcasting rules dont work on vectors properly.\n",
        "\n",
        "#normalising:\n",
        "try:\n",
        "   norm_row = X/row_norms\n",
        "   print(norm_row)\n",
        "except:\n",
        "  print(\"X/row_norms fails ((3,4)/(3,) != broadcasting):due to dimesin reduction and conversion of matrix to vector it became 1D vector. while broadcasting due to vector shape missmatch and rule violation; it fails.\")\n",
        "\n",
        "try:\n",
        "   norm_col = X/col_norms\n",
        "   print(f\"norm_col: {norm_col}, this works due to broadcasting rule was satisfied.\")\n",
        "except:\n",
        "   print(\"X/col_norms fails :due to dimesin reduction and conversion of matrix to vector it became 1D vector. while broadcasting due to vector shape missmatch and rule violation it fails.\")\n",
        "norm_row_dims = X/row_norms_dims\n",
        "norm_col_dims = X/col_norms_dims\n",
        "\n",
        "print(norm_row_dims, norm_col_dims)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIaHB3clpbO9",
        "outputId": "5119c0df-c078-4951-ed45-0af3ce122c2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "normalisation with axis=0 and keepdims=True: [[-1.34164079 -1.34164079 -1.34164079]\n",
            " [-0.4472136  -0.4472136  -0.4472136 ]\n",
            " [ 0.4472136   0.4472136   0.4472136 ]\n",
            " [ 1.34164079  1.34164079  1.34164079]]\n",
            "normalisation with axis=0 and keepdims=False: [[-1.34164079 -1.34164079 -1.34164079]\n",
            " [-0.4472136  -0.4472136  -0.4472136 ]\n",
            " [ 0.4472136   0.4472136   0.4472136 ]\n",
            " [ 1.34164079  1.34164079  1.34164079]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "#norm mean/std\n",
        "X = np.array([\n",
        "    [1, 2, 3],   # row 0\n",
        "    [4, 5, 6],   # row 1\n",
        "    [7, 8, 9],   # row 2\n",
        "    [10,11,12],  # row 3\n",
        "])  # shape (4,3)\n",
        "\n",
        "# column wise\n",
        "col_means_dims = X.mean(axis=0, keepdims=True)    # shape (1, n_features)\n",
        "col_stds_dims  = X.std(axis=0, keepdims=True)     # shape (1, n_features)\n",
        "\n",
        "#row wise\n",
        "row_means_dims = X.mean(axis=1, keepdims=True)    # shape (n_sample, 1)\n",
        "row_stds_dims  = X.std(axis=1, keepdims=True)     # shape (n_sample, 1)\n",
        "\n",
        "# column wise no keepdims true\n",
        "col_means = X.mean(axis=0, keepdims=False)    # shape (n_features, )\n",
        "col_stds  = X.std(axis=0, keepdims=False)     # shape (n_features, )\n",
        "\n",
        "#row wise no keepdims true\n",
        "row_means = X.mean(axis=1, keepdims=False)    # shape (n_sample, )\n",
        "row_stds  = X.std(axis=1, keepdims=False)     # shape (n_sample, )\n",
        "\n",
        "#norm\n",
        "norm_cols_dim = (X - col_means_dims)/col_stds_dims\n",
        "print(f\"normalisation with axis=0 and keepdims=True: {norm_cols_dim}\")\n",
        "\n",
        "#norm without dims = True\n",
        "norm_cols = (X - col_means)/col_stds\n",
        "print(f\"normalisation with axis=0 and keepdims=False: {norm_cols}\")\n",
        "\n",
        "# output tells: How many standard deviations away from the mean each original value is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4w8b4aCly9DV"
      },
      "source": [
        "When you want to ensure shapes match nicely for:\n",
        "\n",
        "- matrix equations\n",
        "- avoiding shape collapse\n",
        "- preventing mistakes during broadcasting\n",
        "- writing neural-network code where shapes must be explicit\n",
        "- keeping dimensions for later concatenations\n",
        "\n",
        "---\n",
        "Shape diagrams (in words)\n",
        "---\n",
        "For row‑wise mean subtraction on X.shape == (4,3):\n",
        "\n",
        "1. Original: X → (4,3).​\n",
        "\n",
        "2. Reduce: row_means = X.mean(axis=1, keepdims=True) → (4,1).​\n",
        "\n",
        "3. Broadcast: X_centered = X - row_means → (4,3) again.​\n",
        "\n",
        "For column‑wise mean subtraction:\n",
        "\n",
        "1. X → (4,3).​\n",
        "\n",
        "2. col_means = X.mean(axis=0, keepdims=True) → (1,3).​\n",
        "\n",
        "3. X_centered = X - col_means → (4,3).​\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjgXSlIaVKci"
      },
      "source": [
        "---\n",
        "Stacking vs concatenation vs split (2D focus)\n",
        "\n",
        "Now for the dataset thinking on\n",
        "(\n",
        "n\n",
        "samples\n",
        ",\n",
        "n\n",
        "features\n",
        ").\n",
        "\n",
        "Definitions:\n",
        "\n",
        "- np.concatenate((a, b), axis=k) → join arrays along existing axis k.​\n",
        "\n",
        "- np.hstack((a, b)) → concatenate along columns for 2D (i.e., axis=1).​\n",
        "\n",
        "- np.vstack((a, b)) → concatenate along rows (i.e., axis=0).​\n",
        "\n",
        "- np.stack((a, b), axis=k) → create a new axis and stack arrays along it.​\n",
        "\n",
        "Key mental notes you asked to write:\n",
        "\n",
        "- “stack adds a new axis, concatenate extends an existing axis.”​\n",
        "\n",
        "- “vstack → more rows (samples); hstack → more columns (features).”\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EekdHXeuvE_",
        "outputId": "5436e6c0-9693-4e3b-b4b9-2ada0cdfa6c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hstack: [1 2 3 4 5 6], shape: (6,), expected : [1,2,3,4,5,6]\n",
            "vstack: [[1 2 3]\n",
            " [4 5 6]], shape: (2, 3), expected : [[1,2,3],[4,5,6]]\n",
            "stack_0: [[1 2 3]\n",
            " [4 5 6]], shape: (2, 3), expected : [[1,2,3],[4,5,6]]\n",
            "stack_2: [[1 4]\n",
            " [2 5]\n",
            " [3 6]], shape: (3, 2), expected : [[1,4],[2,5],[3,6]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.array([1,2,3])\n",
        "b = np.array([4,5,6])\n",
        "\n",
        "#hstack:- concatenate along column\n",
        "hstack = np.hstack([a,b])\n",
        "print(f\"hstack: {hstack}, shape: {hstack.shape}, expected : [1,2,3,4,5,6]\")\n",
        "\n",
        "#vstack:- concatenate along row\n",
        "vstack = np.vstack([a,b])\n",
        "print(f\"vstack: {vstack}, shape: {vstack.shape}, expected : [[1,2,3],[4,5,6]]\")\n",
        "\n",
        "#stack:- axis = 0 along row\n",
        "stack_0 = np.stack([a,b], axis=0)\n",
        "print(f\"stack_0: {stack_0}, shape: {stack_0.shape}, expected : [[1,2,3],[4,5,6]]\")\n",
        "#vstack and stack at axis = 0 are same for two 1D vectors.\n",
        "\n",
        "#stack- axis = 1 along column\n",
        "stack_1 = np.stack([a,b], axis=1)\n",
        "print(f\"stack_2: {stack_1}, shape: {stack_1.shape}, expected : [[1,4],[2,5],[3,6]]\")\n",
        "#in stack at axis = 1 , while creating new axis is added."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHpk4SQjXxAe",
        "outputId": "8d96ae5c-74d5-4601-814c-b57d981d58dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hastck: [[1 2 5 6]\n",
            " [3 4 7 8]], shape: (2, 4), expected : [[1,2,5,6],[3,4,7,8]]\n",
            "vstack: [[1 2]\n",
            " [3 4]\n",
            " [5 6]\n",
            " [7 8]], shape: (4, 2), expected : [[1,2],[3,4],[5,6],[7,8]]\n",
            "stack_0: [[[1 2]\n",
            "  [3 4]]\n",
            "\n",
            " [[5 6]\n",
            "  [7 8]]], shape: (2, 2, 2), expected : [[[1,2],[3,4]],[[5,6],[7,8]]]\n",
            "stack_1: [[[1 2]\n",
            "  [5 6]]\n",
            "\n",
            " [[3 4]\n",
            "  [7 8]]], shape: (2, 2, 2), expected : [[[1,2],[5,6]],[[3,4],[7,8]]]\n"
          ]
        }
      ],
      "source": [
        "# for two 2D matrix\n",
        "\n",
        "a = np.array([[1,2],[3,4]])\n",
        "b = np.array([[5,6],[7,8]])\n",
        "\n",
        "#hstack: concatenate along col\n",
        "hstack = np.hstack([a,b])\n",
        "print(f\"hastck: {hstack}, shape: {hstack.shape}, expected : [[1,2,5,6],[3,4,7,8]]\")\n",
        "\n",
        "#vstack: concatenate along row\n",
        "vstack = np.vstack([a,b])\n",
        "print(f\"vstack: {vstack}, shape: {vstack.shape}, expected : [[1,2],[3,4],[5,6],[7,8]]\")\n",
        "\n",
        "#stack- axis = 0 along row\n",
        "stack_0 = np.stack([a,b], axis = 0)\n",
        "print(f\"stack_0: {stack_0}, shape: {stack_0.shape}, expected : [[[1,2],[3,4]],[[5,6],[7,8]]]\")\n",
        "#stack_0 create dimension for each seperate matrix then concatenate in another dimension and together push in another dimension.\n",
        "\n",
        "#stack- axis = 1 along col\n",
        "stack_1 = np.stack([a,b], axis = 1)\n",
        "print(f\"stack_1: {stack_1}, shape: {stack_1.shape}, expected : [[[1,2],[5,6]],[[3,4],[7,8]]]\")\n",
        "#stack_1 create dimension for each seperate matrix then concatenate in another dimension below it and together push in another dimension."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZklCHslh5n4"
      },
      "source": [
        "vstack and hstack for datasets\n",
        "---\n",
        "\n",
        " Vertical stacking (vstack): combine more samples.\n",
        "---\n",
        "\n",
        "1. Requirements: arrays must have same number of columns (features).​\n",
        "\n",
        "2. Example scenario: you have X_train_part1 and X_train_part2 (two splits with same features).\n",
        "\n",
        "3. If X_original is (5,3) and X_new is (5,2), X_with_new_features is (5,5)\n",
        "\n",
        "4. Pitfall: shapes mismatch:\n",
        "\n",
        "  - Trying np.vstack((X1, X2)) when X1.shape == (3,3) and X2.shape == (3,4) → error because columns differ.​\n",
        "\n",
        "  - Trying np.hstack((X1, X2)) when row counts differ → error.\n",
        "\n",
        ".....................................................................................................................................\n",
        "\n",
        " Horizontal stacking (hstack): add new features (columns).\n",
        "---\n",
        "1. Requirements: arrays must have same number of rows (samples).​\n",
        "\n",
        "2. Example scenario: you engineered new features X_new with same number of samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q69EO0nViylh"
      },
      "source": [
        "np.concatenate vs hstack/vstack\n",
        "---\n",
        "np.concatenate is more general; hstack/vstack are convenience wrappers:\n",
        "\n",
        "- np.hstack((a, b)) ≈ np.concatenate((a, b), axis=1) for 2D arrays.​\n",
        "\n",
        "- np.vstack((a, b)) ≈ np.concatenate((a, b), axis=0) for 2D arrays.​"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_dnYmFIwV5X"
      },
      "source": [
        "vsplit vs hsplit vs split\n",
        "1. 1D array\n",
        "   - hsplit is done vertically, so when queued it goes horizontally side by side.\n",
        "   - vsplit is not valid for 1D array as it required more than 2 rows.\n",
        "   - split :-\n",
        "     - 1D = you can split only along axis 0.\n",
        "     - Axis 1 does NOT exist.\n",
        "\n",
        "2. 2D array\n",
        "   - hsplit is possible.\n",
        "   - vsplit is possible.\n",
        "   - split -\n",
        "     - both axis = 0 and axis = 1 is possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exhetClXkf0S"
      },
      "source": [
        "---\n",
        "\n",
        "Splitting: np.split, hsplit, vsplit\n",
        "---\n",
        "1. For 2D datasets:\n",
        "\n",
        "- np.vsplit(a, indices_or_sections) → split along rows (samples).​\n",
        "\n",
        "- np.hsplit(a, indices_or_sections) → split along columns (features).​\n",
        "\n",
        "- np.split(a, indices_or_sections, axis=k) → generic version.​\n",
        "\n",
        "2. Features + labels split\n",
        "\n",
        "- If data.shape == (5,4) like before, you can do:\n",
        "\n",
        "- Use slicing: X = data[:, :3], y = data[:, 3].​\n",
        "\n",
        "- Or use hsplit: X, y = np.hsplit(data, [3]), so X.shape == (5,3), y.shape == (5,1).​\n",
        "\n",
        "Train/test split manually\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ka0XaNeIxy1s",
        "outputId": "5bf0a56e-ff85-4ceb-94b3-cba1fc36c736"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hsplit 1D: [array([1, 2]), array([3, 4])], expected : [1,2],[3,4]\n",
            "split 1D: [array([1, 2]), array([3, 4])], expected : [1,2],[3,4]\n",
            "vsplit 2D: [array([[1]]), array([[2]]), array([[3]]), array([[4]])], expected : [[[1]],[[2]],[[3]],[[4]] , where each split is a 2D shape\n",
            "shape of each vsplit: (1, 1), (1, 1), (1, 1), (1, 1), which is 2D shaped.\n",
            "split_0_b :[array([[1],\n",
            "       [2]]), array([[3],\n",
            "       [4]])], explected : [[[1]],[[2]],[[3]],[[4]] , where each split is a 2D shape\n",
            "hsplit 2D: [array([[1]]), array([[2]]), array([[3]]), array([[4]])], expected : [[[1]],[[2]],[[3]],[[4]] , where each split is a 2D shape\n",
            "shape of each hsplit: (1, 1), (1, 1), (1, 1), (1, 1), which is 2D shaped.\n",
            "split_0_b :[array([[1, 2]]), array([[3, 4]])], explected : [[[1],[2]],[[3],[4]] , where each split is a 2D shape\n",
            "sHape of split: (1, 2), (1, 2)\n",
            "hsplit 2D: [array([[ 1],\n",
            "       [ 4],\n",
            "       [ 7],\n",
            "       [10]], dtype=int32), array([[ 2],\n",
            "       [ 5],\n",
            "       [ 8],\n",
            "       [11]], dtype=int32), array([[ 3],\n",
            "       [ 6],\n",
            "       [ 9],\n",
            "       [12]], dtype=int32)]\n",
            "vsplit 2D: [array([[1, 2, 3]], dtype=int32), array([[4, 5, 6]], dtype=int32), array([[7, 8, 9]], dtype=int32), array([[10, 11, 12]], dtype=int32)]\n",
            "split_0_2D: [array([[1, 2, 3]], dtype=int32), array([[4, 5, 6]], dtype=int32), array([[7, 8, 9]], dtype=int32), array([[10, 11, 12]], dtype=int32)]\n",
            "split_1_2D: [array([[ 1],\n",
            "       [ 4],\n",
            "       [ 7],\n",
            "       [10]], dtype=int32), array([[ 2],\n",
            "       [ 5],\n",
            "       [ 8],\n",
            "       [11]], dtype=int32), array([[ 3],\n",
            "       [ 6],\n",
            "       [ 9],\n",
            "       [12]], dtype=int32)]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.array([1,2,3,4])\n",
        "\n",
        "# 1D vector\n",
        "#hsplit :- hsplit, NumPy treats 1D arrays as row vectors.So it automatically promotes (4,) → (1,4) internally.\n",
        "hsplit = np.hsplit(a,2)\n",
        "print(f\"hsplit 1D: {hsplit}, expected : [1,2],[3,4]\")\n",
        "\n",
        "#vsplit : vsplit is not applicable on 1D vectors which has only one row.\n",
        "\n",
        "#split:- works only along axis = 0 ,axis=0 refers to the only dimension\n",
        "split_0 = np.split(a,2,axis = 0)\n",
        "print(f\"split 1D: {split_0}, expected : [1,2],[3,4]\")\n",
        "\n",
        "\n",
        "#2D matrix\n",
        "# edge case\n",
        "b = np.array([[1],[2],[3],[4]])\n",
        "\n",
        "#hsplit : hsplit will now work because it has only one column whereas it requires more than 1 column (4,1).\n",
        "\n",
        "#vsplit:\n",
        "vsplit = np.vsplit(b,4)\n",
        "print(f\"vsplit 2D: {vsplit}, expected : [[[1]],[[2]],[[3]],[[4]] , where each split is a 2D shape\")\n",
        "print(f\"shape of each vsplit: {vsplit[0].shape}, {vsplit[1].shape}, {vsplit[2].shape}, {vsplit[3].shape}, which is 2D shaped.\")\n",
        "\n",
        "#split:- axis - 0 will work as its (4,1) matrix , 4 rows can be split to 2.\n",
        "split_0_b = np.split(b,2,axis = 0)\n",
        "print(f\"split_0_b :{split_0_b}, explected : [[[1]],[[2]],[[3]],[[4]] , where each split is a 2D shape\")\n",
        "\n",
        "#split:- axis - 1 will not work as its (4,1) matrix , 1 col cannot be split to 2.\n",
        "\n",
        "\n",
        "# edge case\n",
        "c = np.array([[1,2,3,4]])\n",
        "\n",
        "#hsplit : works with axis = 1 (col)\n",
        "hsplit_edge = np.hsplit(c,4)\n",
        "print(f\"hsplit 2D: {hsplit_edge}, expected : [[[1]],[[2]],[[3]],[[4]] , where each split is a 2D shape\")\n",
        "print(f\"shape of each hsplit: {hsplit_edge[0].shape}, {hsplit_edge[1].shape}, {hsplit_edge[2].shape}, {hsplit_edge[3].shape}, which is 2D shaped.\")\n",
        "\n",
        "#vsplit: vsplit will now work because it has only one row whereas it requires more than 1 row (1,4).\n",
        "\n",
        "#split:- axis - 1 will work as its (1,4) matrix , 4 col can be split to 1.\n",
        "split_1_c = np.split(c,2,axis = 1)\n",
        "print(f\"split_0_b :{split_1_c}, explected : [[[1],[2]],[[3],[4]] , where each split is a 2D shape\")\n",
        "print(f\"sHape of split: {split_1_c[0].shape}, {split_1_c[1].shape}\")\n",
        "#split:- axis - 0 will not work as its (1,4) matrix , 1 rows cannot be split to 2.\n",
        "\n",
        "\n",
        "#2d matrix (4,3)\n",
        "d = X = np.array([\n",
        "    [1., 2., 3.],\n",
        "    [4., 5., 6.],\n",
        "    [7., 8., 9.],\n",
        "    [10.,11.,12.],\n",
        "]).astype(np.int32)\n",
        "\n",
        "#hsplit\n",
        "hsplit_2D = np.hsplit(d,3) # shall split along col\n",
        "print(f\"hsplit 2D: {hsplit_2D}\")\n",
        "\n",
        "#vsplit\n",
        "vsplit_2D = np.vsplit(d,4) # shall split along row\n",
        "print(f\"vsplit 2D: {vsplit_2D}\")\n",
        "\n",
        "#split axis:0 row-wise\n",
        "split_0_2D = np.split(d,4,axis = 0) # shall split along row\n",
        "print(f\"split_0_2D: {split_0_2D}\")\n",
        "\n",
        "#split axis:1 col-wise\n",
        "split_1_2D = np.split(d,3,axis = 1) # shall split along col\n",
        "print(f\"split_1_2D: {split_1_2D}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2P9eA25DEpO"
      },
      "source": [
        "Because hsplit, vsplit, dsplit always assume at least 2D:\n",
        "\n",
        "1. hsplit → split column-wise (axis=1)\n",
        "\n",
        "2. vsplit → split row-wise (axis=0)\n",
        "\n",
        "3. dsplit → split depth-wise (axis=2)\n",
        "\n",
        "For 1D input:\n",
        "\n",
        "1. hsplit & vsplit temporarily reshape it to 2D\n",
        "\n",
        "2. split does NOT reshape → strict axis check\n",
        "\n",
        "- hsplit = axis:1 col\n",
        "- vsplit = axis:0 row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTNAljHnypaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "772e289d-90be-4e59-8d30-835f0e7fa747"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X: [[ 1  2  3]\n",
            " [ 4  5  6]\n",
            " [ 7  8  9]\n",
            " [10 11 12]\n",
            " [13 14 15]], shape: (5, 3)\n",
            "y: [[0]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]], shape: (5, 1)\n",
            "X_train: [[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]], shape: (3, 3)\n",
            "X_test: [[10 11 12]\n",
            " [13 14 15]], shape: (2, 3)\n",
            "y_train: [[0]\n",
            " [1]\n",
            " [0]], shape: (3, 1)\n",
            "y_test: [[1]\n",
            " [0]], shape: (2, 1)\n"
          ]
        }
      ],
      "source": [
        "data = np.array([\n",
        "    [1, 2, 3, 0],\n",
        "    [4, 5, 6, 1],\n",
        "    [7, 8, 9, 0],\n",
        "    [10,11,12,1],\n",
        "    [13,14,15,0],\n",
        "])\n",
        "\n",
        "#([sample sample sample | label])\n",
        "\n",
        "X = data[:, :3]    # first 3 columns\n",
        "y = data[:, 3, np.newaxis]    # last column, preserving 2D shape (n_samples, 1)\n",
        "# Alternatively, y = data[:, 3, np.newaxis]\n",
        "\n",
        "print(f\"X: {X}, shape: {X.shape}\")\n",
        "print(f\"y: {y}, shape: {y.shape}\")\n",
        "X_train = X[:3]\n",
        "X_test  = X[3:]\n",
        "y_train = y[:3]\n",
        "y_test  = y[3:]\n",
        "\n",
        "print(f\"X_train: {X_train}, shape: {X_train.shape}\")\n",
        "print(f\"X_test: {X_test}, shape: {X_test.shape}\")\n",
        "print(f\"y_train: {y_train}, shape: {y_train.shape}\")\n",
        "print(f\"y_test: {y_test}, shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X1 = np.array([[1,2,3],[4,5,6]])     # shape (2,3)\n",
        "X2 = np.array([[7,8,9]])             # shape (1,3)\n",
        "y1 = np.array([0, 1])\n",
        "y2 = np.array([1])\n",
        "\n",
        "X_all = np.concatenate((X1, X2), axis = 0)   # vstack or concatenate axis=0\n",
        "y_all = np.concatenate((y1, y2), axis = 0)   # hstack or concatenate axis=0\n",
        "print(X_all)\n",
        "print(y_all)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LT-45p2_KORX",
        "outputId": "c82e0e7f-0226-47d6-d11e-c9c8a5090055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n",
            "[0 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "X side:\n",
        "\n",
        "X1 = (2,3) and X2 = (1,3)\n",
        "→ same number of columns → can concatenate along axis=0\n",
        "→ vstack works\n",
        "→ concatenate(axis=0) works\n",
        "\n",
        "y side:\n",
        "\n",
        "y1 = (2,) and y2 = (1,)\n",
        "→ 1D so only axis=0 exists\n",
        "→ hstack = concatenate along the only axis → works\n",
        "\n",
        "| Function              | Works on  | Requirement                      | Meaning                      |\n",
        "| --------------------- | --------- | -------------------------------- | ---------------------------- |\n",
        "| `concatenate(axis=0)` | 1D/2D     | same **columns**                 | join rows                    |\n",
        "| `concatenate(axis=1)` | 2D        | same **rows**                    | join columns                 |\n",
        "| `vstack`              | 1D→2D, 2D | same **columns**                 | vertical (row) stacking      |\n",
        "| `hstack`              | 1D or 2D  | 1D → trivial, 2D → same **rows** | horizontal (column) stacking |\n"
      ],
      "metadata": {
        "id": "04bGtzm2Mxh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_basic = np.array([\n",
        "    [1., 2.],\n",
        "    [3., 4.],\n",
        "    [5., 6.],\n",
        "])  # shape (3,2)\n",
        "\n",
        "X_extra = np.array([\n",
        "    [10.],\n",
        "    [20.],\n",
        "    [30.],\n",
        "])  # shape (3,1)\n",
        "\n",
        "X_full = np.hstack((X_basic, X_extra))  # which stacking?\n",
        "print(X_full.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkWPpqvqN8kV",
        "outputId": "35d883b3-ea37-4841-f5f2-88d77566270a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "day5_20NOv"
      ],
      "metadata": {
        "id": "zPD7dezaNIWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "rng = np.random.default_rng(42)\n",
        "uniform_samples = rng.random((10,3)) # shape (10,3): 10 samples, 3 features\n",
        "print(f\"uniform samples: {uniform_samples}\")\n",
        "\n",
        "normal_sample = rng.normal(loc=0.0, scale=1.0, size=(10,3))\n",
        "print(normal_sample)\n",
        "\n",
        "int_sample = rng.integers(0, 10, size=5)\n",
        "print(int_sample)"
      ],
      "metadata": {
        "id": "jN7se5LoN9sq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59de4c58-1813-452d-b00c-d3a14685c389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.77395605 0.43887844 0.85859792]\n",
            " [0.69736803 0.09417735 0.97562235]\n",
            " [0.7611397  0.78606431 0.12811363]\n",
            " [0.45038594 0.37079802 0.92676499]\n",
            " [0.64386512 0.82276161 0.4434142 ]\n",
            " [0.22723872 0.55458479 0.06381726]\n",
            " [0.82763117 0.6316644  0.75808774]\n",
            " [0.35452597 0.97069802 0.89312112]\n",
            " [0.7783835  0.19463871 0.466721  ]\n",
            " [0.04380377 0.15428949 0.68304895]]\n",
            "[[ 2.1416476  -0.40641502 -0.51224273]\n",
            " [-0.81377273  0.61597942  1.12897229]\n",
            " [-0.11394746 -0.84015648 -0.82448122]\n",
            " [ 0.65059279  0.74325417  0.54315427]\n",
            " [-0.66550971  0.23216132  0.11668581]\n",
            " [ 0.2186886   0.87142878  0.22359555]\n",
            " [ 0.67891356  0.06757907  0.2891194 ]\n",
            " [ 0.63128823 -1.45715582 -0.31967122]\n",
            " [-0.47037265 -0.63887785 -0.27514225]\n",
            " [ 1.49494131 -0.86583112  0.96827835]]\n",
            "[8 5 0 7 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "uniform_sample = np.random.rand(10,3) # shape (10,3): 10samples, 3 features\n",
        "print(uniform_sample)\n",
        "\n",
        "normal_sample = np.random.randn(10,3)\n",
        "print(normal_sample)\n",
        "\n",
        "int_sample = np.random.randint(0, 10, size=5)\n",
        "print(int_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bBee8pB8opL",
        "outputId": "df1675ec-75e9-441f-92bb-75526e035832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.37454012 0.95071431 0.73199394]\n",
            " [0.59865848 0.15601864 0.15599452]\n",
            " [0.05808361 0.86617615 0.60111501]\n",
            " [0.70807258 0.02058449 0.96990985]\n",
            " [0.83244264 0.21233911 0.18182497]\n",
            " [0.18340451 0.30424224 0.52475643]\n",
            " [0.43194502 0.29122914 0.61185289]\n",
            " [0.13949386 0.29214465 0.36636184]\n",
            " [0.45606998 0.78517596 0.19967378]\n",
            " [0.51423444 0.59241457 0.04645041]]\n",
            "[[-1.15099358  0.37569802 -0.60063869]\n",
            " [-0.29169375 -0.60170661  1.85227818]\n",
            " [-0.01349722 -1.05771093  0.82254491]\n",
            " [-1.22084365  0.2088636  -1.95967012]\n",
            " [-1.32818605  0.19686124  0.73846658]\n",
            " [ 0.17136828 -0.11564828 -0.3011037 ]\n",
            " [-1.47852199 -0.71984421 -0.46063877]\n",
            " [ 1.05712223  0.34361829 -1.76304016]\n",
            " [ 0.32408397 -0.38508228 -0.676922  ]\n",
            " [ 0.61167629  1.03099952  0.93128012]]\n",
            "[0 4 9 6 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Contrast: uniform vs normal\n",
        "---\n",
        "1. Uniform: all values in interval equally likely; histogram looks flat.​\n",
        "\n",
        "2. Normal: bell‑shaped; most values around mean, tails rare; good for weights or noise.\n",
        "\n",
        "---\n",
        "Normal/Gaussian random\n",
        "---\n",
        "1. rng.normal(loc=0.0, scale=1.0, size=...) or np.random.randn(...) → samples from Normal(mean=loc, std=scale).​\n",
        "\n",
        "2. Default is standard normal\n",
        "N\n",
        "(\n",
        "0\n",
        ",\n",
        "1\n",
        ")\n",
        "N(0,1).\n",
        "\n",
        "---\n",
        "Uniform random (continuous)\n",
        "---\n",
        "1. rng.random(size) or np.random.rand(...) → samples from Uniform(0, 1): any value between 0 and 1 is equally likely.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "FELa08hD_fl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Uniform Sampling — np.random.rand()\n",
        "\n",
        "Uniform sampling means every value in a range is equally likely.\n",
        "\n",
        "Range: 0 to 1 (inclusive of 0, exclusive of 1)\n",
        "\n",
        "- Properties\n",
        "  - Mean ≈ 0.5\n",
        "  - All values between 0 and 1 are equally common.\n",
        "  - No negative numbers ever.\n",
        "\n",
        "- To change range\n",
        "  - Example: range [-1, 1]\n",
        "  - 2 * np.random.rand() - 1\n",
        "\n",
        "---\n",
        "2. Gaussian Sampling — np.random.randn()\n",
        "\n",
        "Gaussian = Normal distribution = bell-curve shaped distribution.\n",
        "\n",
        "- np.random.randn() uses:\n",
        "  - Mean (μ) = 0\n",
        "  - Standard deviation (σ) = 1\n",
        "\n",
        "- Range: technically (-∞, +∞)\n",
        "  - but practically:\n",
        "  - 95% values lie between -2 and +2\n",
        "  - 99.7% lie between -3 and +3\n",
        "\n",
        "- Example: may give: 1.12, -0.44, 2.9, etc.\n",
        "\n",
        "- Properties :\n",
        "  - Values cluster around 0\n",
        "  - Negative values common\n",
        "  - Extreme values possible but rare\n",
        "\n",
        "- To change mean & variance\n",
        "  - Gaussian with mean μ and std σ: μ + σ * np.random.randn()\n",
        "  - ex: 5 + 2 * np.random.randn()"
      ],
      "metadata": {
        "id": "S18zHDv4Btpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "rng = np.random.default_rng(42)\n",
        "\n",
        "x = rng.random((10,3))\n",
        "print(x)\n",
        "\n",
        "y = rng.integers(0, 10, size=(10,))\n",
        "print(y)\n",
        "\n",
        "indices = rng.permutation(len(x))\n",
        "print(indices)\n",
        "\n",
        "x_shuffled = x[indices]\n",
        "y_shuffled = y[indices]\n",
        "\n",
        "print(\"Shuffled x:\\n\", x_shuffled)\n",
        "print(\"Shuffled y:\\n\", y_shuffled)"
      ],
      "metadata": {
        "id": "W7e8ksa29XA3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00443339-3823-4747-86c8-9df5cb7e8936"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.77395605 0.43887844 0.85859792]\n",
            " [0.69736803 0.09417735 0.97562235]\n",
            " [0.7611397  0.78606431 0.12811363]\n",
            " [0.45038594 0.37079802 0.92676499]\n",
            " [0.64386512 0.82276161 0.4434142 ]\n",
            " [0.22723872 0.55458479 0.06381726]\n",
            " [0.82763117 0.6316644  0.75808774]\n",
            " [0.35452597 0.97069802 0.89312112]\n",
            " [0.7783835  0.19463871 0.466721  ]\n",
            " [0.04380377 0.15428949 0.68304895]]\n",
            "[9 7 3 9 4 3 9 3 0 4]\n",
            "[2 7 5 3 8 4 1 9 6 0]\n",
            "Shuffled x:\n",
            " [[0.7611397  0.78606431 0.12811363]\n",
            " [0.35452597 0.97069802 0.89312112]\n",
            " [0.22723872 0.55458479 0.06381726]\n",
            " [0.45038594 0.37079802 0.92676499]\n",
            " [0.7783835  0.19463871 0.466721  ]\n",
            " [0.64386512 0.82276161 0.4434142 ]\n",
            " [0.69736803 0.09417735 0.97562235]\n",
            " [0.04380377 0.15428949 0.68304895]\n",
            " [0.82763117 0.6316644  0.75808774]\n",
            " [0.77395605 0.43887844 0.85859792]]\n",
            "Shuffled y:\n",
            " [3 3 3 9 0 4 7 4 9 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed\n",
        "x = np.random.rand(10, 3)\n",
        "print(x)\n",
        "y = np.random.randint(0, 10, size = 10)\n",
        "print(y)\n",
        "\n",
        "indices = np.random.permutation(len(x))\n",
        "print(indices)\n",
        "x_shuffled = x[indices]\n",
        "y_shuffled = y[indices]\n",
        "\n",
        "print(\"Shuffled x:\\n\", x_shuffled)\n",
        "print(\"Shuffled y:\\n\", y_shuffled)\n"
      ],
      "metadata": {
        "id": "OWY9lgt3IzVM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eff65814-23a8-44dd-a6f0-58087e0e0091"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.42200136 0.36239559 0.31218811]\n",
            " [0.91025685 0.09823054 0.40498863]\n",
            " [0.76001788 0.3033932  0.96587374]\n",
            " [0.24464538 0.86231839 0.96865454]\n",
            " [0.65498889 0.56875456 0.38537936]\n",
            " [0.1901356  0.83860548 0.95118172]\n",
            " [0.13928408 0.84610081 0.71696581]\n",
            " [0.23044406 0.13881872 0.92058622]\n",
            " [0.18351881 0.96636954 0.51727013]\n",
            " [0.0827017  0.75117815 0.27213166]]\n",
            "[9 6 2 2 9 8 0 1 5 2]\n",
            "[9 7 5 0 8 6 3 2 1 4]\n",
            "Shuffled x:\n",
            " [[0.0827017  0.75117815 0.27213166]\n",
            " [0.23044406 0.13881872 0.92058622]\n",
            " [0.1901356  0.83860548 0.95118172]\n",
            " [0.42200136 0.36239559 0.31218811]\n",
            " [0.18351881 0.96636954 0.51727013]\n",
            " [0.13928408 0.84610081 0.71696581]\n",
            " [0.24464538 0.86231839 0.96865454]\n",
            " [0.76001788 0.3033932  0.96587374]\n",
            " [0.91025685 0.09823054 0.40498863]\n",
            " [0.65498889 0.56875456 0.38537936]]\n",
            "Shuffled y:\n",
            " [2 1 8 9 5 0 2 2 6 9]\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shuffling, permutation, and paired permutation\n",
        "---\n",
        "2. shuffle vs permutation\n",
        "- Two key tools:\n",
        "\n",
        "  - rng.shuffle(x) or np.random.shuffle(x)\n",
        "\n",
        "  - In‑place shuffle along first axis: original array is modified.​\n",
        "\n",
        "  - For 2D x → shuffles rows (axis 0) by default.​\n",
        "\n",
        "- rng.permutation(x) or np.random.permutation(x)\n",
        "\n",
        "  - Returns a shuffled copy, does not modify original.​\n",
        "\n",
        "  - If x is an integer n, returns a shuffled np.arange(n)"
      ],
      "metadata": {
        "id": "5MOe99UsIzrF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Why shuffling y with x is important?\n",
        "---\n",
        "\n",
        "consider x = samples; y = labels;\n",
        "- if you shuffle only x it will not match true values ( resulting labels ) in y.\n",
        "- this will lead to error while training the model and after-wards it will predict wrong outputs.\n",
        "---\n",
        "\n",
        "indexing for 2D is according to row-wise."
      ],
      "metadata": {
        "id": "W1U3KbqKEDd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "rng = np.random.default_rng(42)\n",
        "\n",
        "x = rng.random((10,3))\n",
        "print(x)\n",
        "\n",
        "y = rng.integers(0, 10, size=(10,))\n",
        "print(y)\n",
        "\n",
        "perm = np.random.permutation(len(x))\n",
        "\n",
        "x_shuffled = x[perm]\n",
        "y_shuffled = y[perm]\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "batch_idx = perm[:batch_size]\n",
        "print(f\"{batch_idx} \\n\")\n",
        "x_batch = x_shuffled[batch_idx]  # shape (batch_size, n_features)\n",
        "y_batch = y_shuffled[batch_idx]  # shape (batch_size,)\n",
        "\n",
        "print(x_batch, y_batch)\n",
        "\n",
        "n = x.shape[0]\n",
        "for start in range(0, n, batch_size):\n",
        "    end = start + batch_size\n",
        "    batch_idx = perm[start:end]    # slice of the index array\n",
        "    x_batch = x[batch_idx]\n",
        "    y_batch = y[batch_idx]\n",
        "    # ... use this mini-batch\n",
        "print(f\"\\n {x_batch}, {y_batch}\")\n",
        "print(f\"\\n x_batch size: {x_batch.size}, y_batch size: {y_batch.size}\")\n",
        "\n",
        "idx = [1, 3, 7]\n",
        "x_selected = x[idx]\n",
        "y_selected = y[idx]\n",
        "\n",
        "print(f\"x selected :{x_selected}, shape: {x_selected.shape}, strides: {x_selected.strides}, type: {x_selected.flags}, view or copy: {x_selected.base} : none means copy.\")\n",
        "print(f\"y selected :{y_selected}, shape: {y_selected.shape}, strides: {y_selected.strides}, type: {y_selected.flags}, view or copy: {y_selected.base} : none means copy.\")\n",
        "\n",
        "mask1 = x[:, 0] > 0.25     # shape (n,)\n",
        "mask2 = x[:, 0] > 0.25    # shape (n,)\n",
        "x_pos = x[mask1]           # all rows where first feature > 0\n",
        "y_pos = y[mask2]           # corresponding labels\n",
        "print(f\"x_pos: {x_pos},  strides: {x_pos.strides}, type: {x_pos.flags}, view or copy: {x_pos.base} : none means copy.\")\n",
        "print(f\"y_pos: {y_pos},  strides: {y_pos.strides}, type: {y_pos.flags}, view or copy: {y_pos.base} : none means copy.\")\n",
        "\n",
        "for start in range(0, n, batch_size):\n",
        "    end = start + batch_size\n",
        "    batch_idx = rng.choice(n, size=batch_size, replace=True)\n",
        "    x_batch = x[batch_idx]\n",
        "    y_batch = y[batch_idx]\n",
        "    # ... use this mini-batch\n",
        "print(f\"\\n {x_batch}, {y_batch}\")\n",
        "print(f\"\\n x_batch size: {x_batch.size}, y_batch size: {y_batch.size}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpNOu9lONlBY",
        "outputId": "8e5e36a1-48bd-41b0-9dbc-248209ec8596"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.77395605 0.43887844 0.85859792]\n",
            " [0.69736803 0.09417735 0.97562235]\n",
            " [0.7611397  0.78606431 0.12811363]\n",
            " [0.45038594 0.37079802 0.92676499]\n",
            " [0.64386512 0.82276161 0.4434142 ]\n",
            " [0.22723872 0.55458479 0.06381726]\n",
            " [0.82763117 0.6316644  0.75808774]\n",
            " [0.35452597 0.97069802 0.89312112]\n",
            " [0.7783835  0.19463871 0.466721  ]\n",
            " [0.04380377 0.15428949 0.68304895]]\n",
            "[9 7 3 9 4 3 9 3 0 4]\n",
            "[8 3 9 5] \n",
            "\n",
            "[[0.7611397  0.78606431 0.12811363]\n",
            " [0.22723872 0.55458479 0.06381726]\n",
            " [0.64386512 0.82276161 0.4434142 ]\n",
            " [0.69736803 0.09417735 0.97562235]] [3 3 4 7]\n",
            "\n",
            " [[0.7611397  0.78606431 0.12811363]\n",
            " [0.64386512 0.82276161 0.4434142 ]], [3 4]\n",
            "\n",
            " x_batch size: 6, y_batch size: 2\n",
            "x selected :[[0.69736803 0.09417735 0.97562235]\n",
            " [0.45038594 0.37079802 0.92676499]\n",
            " [0.35452597 0.97069802 0.89312112]], shape: (3, 3), strides: (24, 8), type:   C_CONTIGUOUS : True\n",
            "  F_CONTIGUOUS : False\n",
            "  OWNDATA : True\n",
            "  WRITEABLE : True\n",
            "  ALIGNED : True\n",
            "  WRITEBACKIFCOPY : False\n",
            ", view or copy: None : none means copy.\n",
            "y selected :[7 9 3], shape: (3,), strides: (8,), type:   C_CONTIGUOUS : True\n",
            "  F_CONTIGUOUS : True\n",
            "  OWNDATA : True\n",
            "  WRITEABLE : True\n",
            "  ALIGNED : True\n",
            "  WRITEBACKIFCOPY : False\n",
            ", view or copy: None : none means copy.\n",
            "x_pos: [[0.77395605 0.43887844 0.85859792]\n",
            " [0.69736803 0.09417735 0.97562235]\n",
            " [0.7611397  0.78606431 0.12811363]\n",
            " [0.45038594 0.37079802 0.92676499]\n",
            " [0.64386512 0.82276161 0.4434142 ]\n",
            " [0.82763117 0.6316644  0.75808774]\n",
            " [0.35452597 0.97069802 0.89312112]\n",
            " [0.7783835  0.19463871 0.466721  ]],  strides: (24, 8), type:   C_CONTIGUOUS : True\n",
            "  F_CONTIGUOUS : False\n",
            "  OWNDATA : True\n",
            "  WRITEABLE : True\n",
            "  ALIGNED : True\n",
            "  WRITEBACKIFCOPY : False\n",
            ", view or copy: None : none means copy.\n",
            "y_pos: [9 7 3 9 4 9 3 0],  strides: (8,), type:   C_CONTIGUOUS : True\n",
            "  F_CONTIGUOUS : True\n",
            "  OWNDATA : True\n",
            "  WRITEABLE : True\n",
            "  ALIGNED : True\n",
            "  WRITEBACKIFCOPY : False\n",
            ", view or copy: None : none means copy.\n",
            "\n",
            " [[0.22723872 0.55458479 0.06381726]\n",
            " [0.82763117 0.6316644  0.75808774]\n",
            " [0.04380377 0.15428949 0.68304895]\n",
            " [0.64386512 0.82276161 0.4434142 ]], [3 9 4 4]\n",
            "\n",
            " x_batch size: 12, y_batch size: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "C‑order vs F‑order\n",
        "---\n",
        "\n",
        "-  C‑order (row‑major): default in NumPy.​\n",
        "\n",
        "   - Elements in the same row are stored next to each other in memory.\n",
        "\n",
        "   - Last index varies fastest.\n",
        "\n",
        "- F‑order (column‑major): Fortran style.​\n",
        "\n",
        "  - Elements in the same column are adjacent.\n",
        "\n",
        "  - First index varies fastest.\n",
        "\n",
        "Conceptual picture for a 2×3 array [[a, b, c], [d, e, f]]:\n",
        "---\n",
        "- C‑order memory: [a, b, c, d, e, f].\n",
        "\n",
        "- F‑order memory: [a, d, b, e, c, f]"
      ],
      "metadata": {
        "id": "FQLFdrqddsPw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TTWZDKW3OIli"
      },
      "execution_count": 27,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}