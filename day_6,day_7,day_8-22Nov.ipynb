{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrd+fBInZQbal5cnFzgWxJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satyamnewale/numpy-Book/blob/main/day_6%2Cday_7%2Cday_8-22Nov.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "day_6-21Nov"
      ],
      "metadata": {
        "id": "UPVg3Eloy-9t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ufuncs are implemented in C and operate on whole arrays → huge speedup vs Python loops.\n",
        "\n",
        "ufunc is divided into two parts Core element‑wise ufuncs and reduction ufuncs:\n",
        "\n",
        "1. Core element‑wise ufuncs,\n",
        "All assume x is an ndarray; results broadcast to shape of input.​\n",
        "\n",
        "- np.exp(x) → computes\n",
        "e\n",
        "x\n",
        "  for each element.​\n",
        "\n",
        "- np.log(x) → natural log of each element (base\n",
        "e\n",
        "e); domain:\n",
        "x\n",
        ">\n",
        "0\n",
        "x>0 (0 gives\n",
        "−∞, negatives → nan).​\n",
        "\n",
        "- np.sqrt(x) → square root; domain:\n",
        "x≥0 (negatives → complex or nan depending on dtype).​\n",
        "\n",
        "- np.sin(x), np.tanh(x) → standard trig/hyperbolic functions element‑wise.​\n",
        "\n",
        "- np.abs(x) → absolute value.​\n",
        "\n",
        "- np.ceil(x), np.floor(x) → round up/down element‑wise.\n",
        "\n",
        "  - Pitfalls:\n",
        "\n",
        "    - np.log(0) → -inf, np.log of negative real → nan (need to clamp with eps).​\n",
        "\n",
        "    - np.exp(large_positive) can overflow to inf (softmax issue)\n",
        "\n",
        "2. Reduction ufuncs,\n",
        "Reduction ufuncs aggregate along axes.​\n",
        "\n",
        "- np.sum(x, axis=...) → sum.\n",
        "\n",
        "- np.max, np.min → max/min.\n",
        "\n",
        "- np.prod → product.\n",
        "\n",
        "- np.mean → mean.\n",
        "\n",
        "They support axis, keepdims, dtype, out etc., and are crucial for normalizations, softmax denominators, losses."
      ],
      "metadata": {
        "id": "5CwN05gMzZDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#component-wise ufuncs\n",
        "import numpy as np\n",
        "\n",
        "x= np.array([2.0, -1 , 3.5, -4., 0, 0.1 , 4.1])\n",
        "\n",
        "exp = np.exp(x)\n",
        "log = np.log(x)\n",
        "sqrt = np.sqrt(x)\n",
        "sin = np.sin(x)\n",
        "abs = np.abs(x)\n",
        "ceil = np.ceil(x)\n",
        "floor = np.floor(x)\n",
        "cos = np.cos(x)\n",
        "tan = np.tan(x)\n",
        "print(f\"exp : {exp}, base:{exp.base} \\n\")\n",
        "print(f\"log : {log}, base:{log.base} \\n\")\n",
        "print(f\"sqrt : {sqrt}, base:{sqrt.base} \\n\")\n",
        "print(f\"sin : {sin}, base:{sin.base} \\n\")\n",
        "print(f\"abs : {abs}, base:{abs.base} \\n\")\n",
        "print(f\"ceil : {ceil}, base:{ceil.base} \\n\")\n",
        "print(f\"floor : {floor}, base:{floor.base} \\n\")\n",
        "print(f\"cos : {cos}, base:{cos.base} \\n\")\n",
        "print(f\"tan : {tan}, base:{tan.base} \\n\")\n",
        "\n",
        "#sqrt gave error due to value -1\n",
        "#log of negative gives nan."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNdKf2c9zKzi",
        "outputId": "d4a38078-87a8-4ed4-bb92-b72b9ffe0eb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "exp : [7.38905610e+00 3.67879441e-01 3.31154520e+01 1.83156389e-02\n",
            " 1.00000000e+00 1.10517092e+00 6.03402876e+01], base:None \n",
            "\n",
            "log : [ 0.69314718         nan  1.25276297         nan        -inf -2.30258509\n",
            "  1.41098697], base:None \n",
            "\n",
            "sqrt : [1.41421356        nan 1.87082869        nan 0.         0.31622777\n",
            " 2.02484567], base:None \n",
            "\n",
            "sin : [ 0.90929743 -0.84147098 -0.35078323  0.7568025   0.          0.09983342\n",
            " -0.81827711], base:None \n",
            "\n",
            "abs : [2.  1.  3.5 4.  0.  0.1 4.1], base:None \n",
            "\n",
            "ceil : [ 2. -1.  4. -4.  0.  1.  5.], base:None \n",
            "\n",
            "floor : [ 2. -1.  3. -4.  0.  0.  4.], base:None \n",
            "\n",
            "cos : [-0.41614684  0.54030231 -0.93645669 -0.65364362  1.          0.99500417\n",
            " -0.57482395], base:None \n",
            "\n",
            "tan : [-2.18503986 -1.55740772  0.37458564 -1.15782128  0.          0.10033467\n",
            "  1.42352648], base:None \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4081877265.py:6: RuntimeWarning: divide by zero encountered in log\n",
            "  log = np.log(x)\n",
            "/tmp/ipython-input-4081877265.py:6: RuntimeWarning: invalid value encountered in log\n",
            "  log = np.log(x)\n",
            "/tmp/ipython-input-4081877265.py:7: RuntimeWarning: invalid value encountered in sqrt\n",
            "  sqrt = np.sqrt(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reduction ufuncs\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "a = np.arange(0,24,2).reshape(3,4)\n",
        "print(f\"a: {a} \\n\")\n",
        "col_mean = a.mean(axis=0, keepdims=True) # shape (1, features)\n",
        "row_max = a.max(axis=1, keepdims=True)   # shape (batch, 1)\n",
        "print(f\"col_mean : {col_mean} \\n\")\n",
        "print(f\"row_max : {row_max} \\n\")\n",
        "\n",
        "row_mean = a.mean(axis=1, keepdims=True)\n",
        "print(f\"row_mean : {row_mean} \\n\")\n",
        "\n",
        "row_min = a.min(axis=1, keepdims=True)\n",
        "print(f\"row_min : {row_min} \\n\")\n",
        "\n",
        "row_sum = a.sum(axis=1, keepdims=True)\n",
        "print(f\"row_sum : {row_sum} \\n\")\n",
        "\n",
        "col_sum = a.sum(axis=0, keepdims=True)\n",
        "print(f\"col_sum : {col_sum}\")\n",
        "\n",
        "row_prod = a.prod(axis=1, keepdims=True)\n",
        "print(f\"row_prod : {row_prod} \\n\")\n",
        "\n",
        "relu_x = np.where(a > 5, a, 0.0)\n",
        "print(f\"relu_x : {relu_x} , base:{relu_x.base} \\n\")\n",
        "\n",
        "clamped_low = np.where(a < 10, 10, a)\n",
        "print(f\"clamped_low : {clamped_low}, base:{clamped_low.base} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElxrQq860wEi",
        "outputId": "b66ad36e-e6e4-449e-97f3-fa9a58ffa1f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a: [[ 0  2  4  6]\n",
            " [ 8 10 12 14]\n",
            " [16 18 20 22]] \n",
            "\n",
            "col_mean : [[ 8. 10. 12. 14.]] \n",
            "\n",
            "row_max : [[ 6]\n",
            " [14]\n",
            " [22]] \n",
            "\n",
            "row_mean : [[ 3.]\n",
            " [11.]\n",
            " [19.]] \n",
            "\n",
            "row_min : [[ 0]\n",
            " [ 8]\n",
            " [16]] \n",
            "\n",
            "row_sum : [[12]\n",
            " [44]\n",
            " [76]] \n",
            "\n",
            "col_sum : [[24 30 36 42]]\n",
            "row_prod : [[     0]\n",
            " [ 13440]\n",
            " [126720]] \n",
            "\n",
            "relu_x : [[ 0.  0.  0.  6.]\n",
            " [ 8. 10. 12. 14.]\n",
            " [16. 18. 20. 22.]] , base:None \n",
            "\n",
            "clamped_low : [[10 10 10 10]\n",
            " [10 10 12 14]\n",
            " [16 18 20 22]], base:None \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "np.where and np.clip for conditional logic and clamping\n",
        "---\n",
        "1. np.where as vectorized if‑else:\n",
        "\n",
        "  - np.where(condition, x, y) picks from x where condition is True, else from y, broadcasting all three:\n",
        "\n",
        "    - Conceptual syntax: out = np.where(condition, value_if_true, value_if_false)\n",
        "\n",
        "\n",
        "2. np.clip(x, a_min, a_max) clamps each element to the interval [a_min, a_max].​\n",
        "\n",
        " -  Values < a_min become a_min.\n",
        "\n",
        " -  Values > a_max become a_max."
      ],
      "metadata": {
        "id": "Rbm5ph054tpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "A = np.array([12, 14, 13, 1500, 14, 13, 16, 15, 14, 40])\n",
        "\n",
        "s = A.std().reshape(1,)\n",
        "m = A.mean().reshape(1,)\n",
        "med = np.median(A).reshape(1,)\n",
        "\n",
        "print(f\"a: {A} \\n\")\n",
        "print(f\"s: {s} \\n\")\n",
        "print(f\"m: {m} \\n\")\n",
        "print(f\"med: {med} \\n\")\n",
        "\n",
        "mask = np.abs(A - m) > 2 * s\n",
        "print(mask)\n",
        "\n",
        "x_fixed = np.where(mask, med, A)\n",
        "print(x_fixed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCDOdnpH2inl",
        "outputId": "e14511e6-b79f-41fc-ef61-a8bb266b340c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a: [  12   14   13 1500   14   13   16   15   14   40] \n",
            "\n",
            "s: [445.03605472] \n",
            "\n",
            "m: [165.1] \n",
            "\n",
            "med: [14.] \n",
            "\n",
            "[False False False  True False False False False False False]\n",
            "[12. 14. 13. 14. 14. 13. 16. 15. 14. 40.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "pixels = np.array([[-20, 50, 120],\n",
        "                   [260, 500, 180]])\n",
        "\n",
        "clipped_pixels = np.clip(pixels, 0, 255)\n",
        "\n",
        "print(clipped_pixels)\n"
      ],
      "metadata": {
        "id": "Y6papavSDIGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Activation functions via ufuncs (vectorized)\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def leaky_relu(x, alpha=0.01):\n",
        "    return np.where(x > 0, x, alpha * x)\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def tanh(x):\n",
        "    return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
        "\n",
        "def softmax_unstable(x):\n",
        "    exp_x = np.exp(x)\n",
        "    return exp_x / np.sum(exp_x, axis = 1, keepdims = True)\n",
        "\n"
      ],
      "metadata": {
        "id": "TzJ1HyM3IHkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Numerical stability: overflow, underflow, precision\n",
        "\n",
        "1. **Overflow**: number too large in magnitude to represent; result becomes inf or -inf.​​\n",
        "\n",
        "- Example: np.exp(1000) in float32 -> inf (can affect gradient).\n",
        "\n",
        "2. **Underflow**: number too close to zero; result becomes 0.​\n",
        "\n",
        "- Example: np.exp(-1000) underflows to 0.\n",
        "- Pitfalls:\n",
        "Probabilities become 0 → log(0) = -inf\n",
        "- Loss becomes NaN.\n",
        "\n",
        "3. **Floating**‑point precision: real numbers stored with limited bits → many reals collapse to same float; small differences can be lost .\n",
        "\n",
        " Numerical stability means rewriting mathematically equivalent formulas so that intermediate values stay in safe ranges and precision is preserved.\n",
        "\n",
        " Numerical stability = turning mathematically equivalent expressions into ones that behave correctly in floating point."
      ],
      "metadata": {
        "id": "MfRKw6Z4JHeh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Floating-Point Precision: Floating-point numbers use finite bits (32 or 64). Many real numbers cannot be represented exactly → rounding errors.\n",
        "\n",
        "print(0.1+0.2)\n",
        "\n",
        "#Pitfalls:\n",
        "#Subtraction of nearly-equal numbers → “catastrophic cancellation”\n",
        "#Variance calculation blows up if mean is large\n",
        "\n",
        "#Edge Cases:\n",
        "#(x - x.mean()) stable\n",
        "#(x**2 - (x.mean())**2) unstable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGS3aqwDJnHY",
        "outputId": "a76bc029-08cd-48b0-9798-4ead1f0f51eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.30000000000000004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = [1000, 1001, 999]\n",
        "\n",
        "def stable_softmax(logits):\n",
        "    # step 1: row_max = logits.max(axis=1, keepdims=True)\n",
        "    row_max = logits.max(axis=1, keepdims=True)\n",
        "    # step 2: shifted = logits - row_max\n",
        "    shifted = logits - row_max\n",
        "    # step 3: exp_vals = np.exp(shifted)\n",
        "    exp_vals = np.exp(shifted)\n",
        "    # step 4: probs = exp_vals / exp_vals.sum(axis=1, keepdims=True)\n",
        "    probs = exp_vals / exp_vals.sum(axis=1, keepdims=True)\n",
        "    return probs\n",
        "\n",
        "# Fix: Reshape the 1D array to a 2D array (1, N) before passing to stable_softmax\n",
        "probs = stable_softmax(np.array(logits).reshape(1, -1))\n",
        "print(probs)\n",
        "\n",
        "def stable_log_softmax(logits):\n",
        "    # m = logits.max(...)\n",
        "    m = logits.max(axis=1, keepdims=True)\n",
        "    # shifted = logits - m\n",
        "    shifted = logits - m\n",
        "    # lse = m + np.log(np.sum(np.exp(shifted), axis=1, keepdims=True))\n",
        "    lse = m + np.log(np.sum(np.exp(shifted), axis=1, keepdims=True))\n",
        "    # return logits - lse\n",
        "    return logits - lse\n",
        "\n",
        "log_probs = stable_log_softmax(np.array(logits).reshape(1, -1))\n",
        "print(log_probs)\n",
        "\n",
        "def stable_normalize(x, eps=1e-8):\n",
        "    # mean = x.mean(axis=1, keepdims=True)\n",
        "    mean = x.mean(axis=1, keepdims=True)\n",
        "    # std = x.std(axis=1, keepdims=True)\n",
        "    std = x.std(axis=1, keepdims=True)\n",
        "    # return (x - mean) / (std + eps)\n",
        "    return (x - mean) / (std + eps)\n",
        "\n",
        "normalize = stable_normalize(np.array(logits).reshape(1, -1))\n",
        "print(normalize)\n",
        "\n",
        "def cross_entropy_from_logits(logits, y):\n",
        "    # log_probs = stable_log_softmax(logits)\n",
        "    log_probs = stable_log_softmax(logits)\n",
        "    # pick = log_probs[np.arange(batch), y]\n",
        "    pick = log_probs[np.arange(logits.shape[0]), y]\n",
        "    # loss = -pick.mean()\n",
        "    loss = -pick.mean()\n",
        "    # return loss\n",
        "    return loss\n",
        "\n",
        "y = np.array([1])\n",
        "loss = cross_entropy_from_logits(np.array(logits).reshape(1, -1), y)\n",
        "print(loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AE4raJRLKe6",
        "outputId": "cfa758b1-579d-4a37-e71d-cf1985f3b90f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.24472847 0.66524096 0.09003057]]\n",
            "[[-1.40760596 -0.40760596 -2.40760596]]\n",
            "[[ 0.          1.22474486 -1.22474486]]\n",
            "0.40760596444442854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "day_7-22Nov"
      ],
      "metadata": {
        "id": "C33nZOZijR-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([1,2,3])   # shape (3,)\n",
        "print((x[:, np.newaxis]).shape)       # shape (3,1)\n",
        "x[np.newaxis, :]        # shape (1,3)\n",
        "print(x,x.shape)\n",
        "\n",
        "np.expand_dims(x, axis=0)   # shape (1,3)\n",
        "np.expand_dims(x, axis=1)   # shape (3,1)\n"
      ],
      "metadata": {
        "id": "zCPPFudxPOH6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56023875-2b10-4e11-d9d1-dca4c44f204e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 1)\n",
            "[1 2 3] (3,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#task 1\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "batch = 64\n",
        "seq_len = 120\n",
        "features = 32\n",
        "\n",
        "x = np.random.randn(batch, seq_len, features)\n",
        "print(x.shape)\n",
        "\n",
        "#Normalize per feature across BOTH batch & seq\n",
        "mean = np.mean(x,axis = (0,1), keepdims = True)\n",
        "std = np.std(x,axis = (0,1), keepdims = True)\n",
        "\n",
        "x_norm_batch_seq = (x - mean)/std\n",
        "print(x_norm_batch_seq.shape)\n",
        "\n",
        "#Normalize per feature across ONLY batch\n",
        "mean = x.mean(axis=0, keepdims=True)   # shape (1, seq_len, features)\n",
        "std  = x.std(axis=0, keepdims=True)    # shape (1, seq_len, features)\n",
        "\n",
        "x_norm_batch = (x - mean) / std\n",
        "print(x_norm_batch.shape)\n",
        "\n",
        "#broadcasting will work in both because it works from right to left.\n",
        "# mean- (1,120,32), std- (1,120,32) right to left work\n",
        "\n",
        "#Add a bias vector (features,) to batch (64, 120, features)\n",
        "bias = np.random.randn(features)\n",
        "print(bias.shape)\n",
        "\n",
        "y = x + bias\n",
        "print(y.shape)\n",
        "\n",
        "#broadcasting will work because x = (64,120,32) ,y = ( , ,32) -> right to left\n",
        "\n",
        "#For images (50, 64, 64, 3)\n",
        "img = np.random.randn(50, 64, 64, 3)\n",
        "#Multiply entire tensor by a scalar\n",
        "new_img = img + 1.2 # scalar broadcasting\n",
        "\n",
        "brightness = np.array([10, -5, 0])\n",
        "new_img = img + brightness #broadcasting will work\n",
        "print(new_img.shape)\n",
        "\n",
        "# illegal broadcasting\n",
        "cast = np.random.rand(120)\n",
        "\n",
        "try:\n",
        "  x + cast\n",
        "except :\n",
        "  print(f\"x + cast will not work because \\n 1. x.shape = (64,120,32) \\n 2. cast.shape = (120,) \\n 3. compare broadcasting: (64,120,32) and ( , ,120) \\n 4. 120 != 32 ,120 -> stretch 1 so possible ,64 -> stretch 1 so possible.\\n 5. one condition not followed : elem not match from right to left. \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDF6LDngjWTW",
        "outputId": "b6f5da86-d546-4550-8660-11b2dbcf249e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 120, 32)\n",
            "(64, 120, 32)\n",
            "(64, 120, 32)\n",
            "(32,)\n",
            "(64, 120, 32)\n",
            "(50, 64, 64, 3)\n",
            "x + cast will not work because \n",
            " 1. x.shape = (64,120,32) \n",
            " 2. cast.shape = (120,) \n",
            " 3. compare broadcasting: (64,120,32) and ( , ,120) \n",
            " 4. 120 != 32 ,120 -> stretch 1 so possible ,64 -> stretch 1 so possible.\n",
            " 5. one condition not followed : elem not match from right to left. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# task 2\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "batch = 100\n",
        "seq_len = 20\n",
        "embed_dim = 16\n",
        "\n",
        "x = np.random.randn(batch, seq_len, embed_dim)\n",
        "print(x.shape)\n",
        "\n",
        "y = np.random.randint(0, 5, size=(100,))\n",
        "print(y.shape)\n",
        "\n",
        "perm = np.random.permutation(len(x))\n",
        "x = x[perm]\n",
        "y = y[perm]\n",
        "\n",
        "#this ensures x[0] matches y[0]\n",
        "\n",
        "#pick batch size:\n",
        "batch_size = 16\n",
        "\n",
        "x_batches = []\n",
        "y_batches = []\n",
        "num_batch = len(x) // batch_size\n",
        "for i in range(num_batch):\n",
        "    start = i * batch_size\n",
        "    end = start + batch_size\n",
        "\n",
        "    x_batches.append(x[start:end])\n",
        "    y_batches.append(y[start:end])\n",
        "\n",
        "print(f\"x_batches: {len(x_batches)} , shape: {x_batches[0].shape}\") # should be (batch_size, seq_len, embed_dim)\n",
        "print(f\"y_batches: {len(y_batches)} , shape: {y_batches[0].shape} \") # should be (batch_size,)\n",
        "\n",
        "#simple check\n",
        "i = 5\n",
        "b = 0\n",
        "\n",
        "print(x_batches[b][i][0][:5])   # print first 5 numbers of first timestep\n",
        "print(y_batches[b][i])\n",
        "\n",
        "#Then check the original data:\n",
        "global_index = b*batch_size + i\n",
        "print(x[global_index][0][:5])\n",
        "print(y[global_index])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH6Twli4nXqZ",
        "outputId": "3f9612b8-8176-43d2-bcae-3c4119fb3b37"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 20, 16)\n",
            "(100,)\n",
            "x_batches: 6 , shape: (16, 20, 16)\n",
            "y_batches: 6 , shape: (16,) \n",
            "[ 0.06410256 -0.14726983 -0.28948327  1.71077578  0.42602501]\n",
            "4\n",
            "[ 0.06410256 -0.14726983 -0.28948327  1.71077578  0.42602501]\n",
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "day_8-22Nov"
      ],
      "metadata": {
        "id": "zxT88eW2Accb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# in_place vs out_of-place\n",
        "- out-of-place - operation produce new array object and assign it to new memory block.eg: b = a*2 - a unchanged, b is new array.\n",
        "- in-place - the operation modifies existing array memory without allocating a new array. Example idea: a *= 2 modifies a in place.\n",
        "\n",
        "Why it matters: out-of-place allocates memory (which costs both RAM and time to allocate + copy). In-place avoids allocation and may be much faster and reduce peak memory usage.\n",
        "\n",
        "# View vs copy\n",
        "\n",
        "- View: a new ndarray object that references the same memory buffer as the original but with different shape, strides, or slicing.\n",
        "\n",
        "Example: v = a[10:20] — usually returns a view.\n",
        "\n",
        "- Copy: a completely new array with its own data.\n",
        "\n",
        "Example: c = a[::2].copy() or c = a[fancy_index] (fancy indexing → copy).\n",
        "\n",
        "# np.shares_memory\n",
        "\n",
        "Use np.shares_memory(a, b) to check if two arrays possibly share the same memory block (True means modification of one may affect the other).\n",
        "\n",
        "# .flags\n",
        "\n",
        "a.flags shows properties: C_CONTIGUOUS (row-major), F_CONTIGUOUS (column-major), WRITEABLE, etc. Contiguity affects speed of traversal.\n",
        "\n",
        "# Strides & layout\n",
        "\n",
        "- a.strides tells how many bytes to step to move along each axis.\n",
        "\n",
        "- Contiguous arrays (C-order) are faster for many C loops; Fortran-order may be faster for column-major access patterns.\n",
        "\n",
        "- Non-contiguous strides (resulting from transposes or some slicing) can make elementwise loops slower because memory jumps reduce cache locality.\n",
        "\n",
        "# Vectorization\n",
        "\n",
        "- Rewriting computation to use whole-array operations (NumPy ufuncs, BLAS-backed ops) instead of Python-level loops.\n",
        "\n",
        "- Elementwise vectorized operations are implemented in C and often use efficient inner loops and CPU features (SIMD). Linear algebra routines can call BLAS/LAPACK which are highly optimized.\n",
        "\n",
        "- This is helpful to optimise GPU/CPU.\n",
        "\n",
        "---\n",
        "edge case:\n",
        "\n",
        " Use np.add(a, b, out=a) or np.multiply(a, 2, out=a) to avoid temporaries. This is often safe and efficient.\n",
        "\n",
        " a = (a + b) * (c - d) can create multiple temporaries. Break into steps using out= or in-place updates to reduce allocations."
      ],
      "metadata": {
        "id": "_F9pVFR6Ajge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = np.arange(10)\n",
        "v = a[2:7]          # view\n",
        "v[0] = 999          # a[2] is now 999\n",
        "c = a[[2,4,6]]      # fancy indexing -> copy\n",
        "print(f\"c:{c}, base: {c.base}\")\n",
        "c[0] = -1           # a unchanged\n",
        "print(c)\n",
        "x = np.arange(6.0)\n",
        "np.multiply(x, 2, out=x)   # in-place doubling\n",
        "# This avoids allocation of a fresh array\n",
        "\n",
        "y = x.T            # transposed view (non-C-contiguous)\n",
        "y_c = np.ascontiguousarray(y)  # make contiguous copy for fast ops\n",
        "\n",
        "print(y_c.flags)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2dTWe5kCJCv",
        "outputId": "d54d825f-957e-4d78-9266-840b516f72dd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c:[999   4   6], base: None\n",
            "[-1  4  6]\n",
            "  C_CONTIGUOUS : True\n",
            "  F_CONTIGUOUS : True\n",
            "  OWNDATA : False\n",
            "  WRITEABLE : True\n",
            "  ALIGNED : True\n",
            "  WRITEBACKIFCOPY : False\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 10 million floats → normalize → scale → clip (heavy operation.)\n",
        "\n",
        "import numpy as np\n",
        "import time, psutil, os\n",
        "\n",
        "process = psutil.Process(os.getpid())\n",
        "def mem(): return process.memory_info().rss / 1024**2\n",
        "\n",
        "np.random.seed(42)\n",
        "N = 10000000\n",
        "\n",
        "a = np.random.randn(N)\n",
        "print(a.shape,a.dtype)\n",
        "\n",
        "print(\"Before:\", mem())\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "#normalize:\n",
        "mean = a.mean()\n",
        "std = a.std()\n",
        "a_norm = (a - mean) / std\n",
        "print(a_norm)\n",
        "\n",
        "#scale:\n",
        "a_scaled = a_norm * 1.2\n",
        "\n",
        "#clip\n",
        "a_clipped = np.clip(a_scaled, -1, 1)\n",
        "print(a_clipped)\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "print(\"After:\", mem())\n",
        "print(\"Elapsed:\", t1 - t0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCuC37IhHSt7",
        "outputId": "1378f5db-f8c3-4092-fff8-975965eb5851"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000000,) float64\n",
            "Before: 736.015625\n",
            "[ 0.49677136 -0.13819847  0.6477437  ...  1.46700064  0.64446342\n",
            "  0.92366338]\n",
            "[ 0.59612564 -0.16583816  0.77729244 ...  1.          0.77335611\n",
            "  1.        ]\n",
            "After: 774.1640625\n",
            "Elapsed: 0.22082281112670898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#optimised way\n",
        "import numpy as np\n",
        "import time, psutil, os\n",
        "\n",
        "process = psutil.Process(os.getpid())\n",
        "def mem(): return process.memory_info().rss / 1024**2\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "a1 = np.empty(N, dtype=np.float32)\n",
        "a1 = np.random.randn(10000000).astype(a1.dtype, copy=False)\n",
        "print(a1.shape,a1.dtype)\n",
        "\n",
        "print(\"Before:\", mem())\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "#normalize:\n",
        "mean = a1.mean()\n",
        "std = a1.std()\n",
        "\n",
        "np.subtract(a1, mean, out=a1) # now a holds a - mean\n",
        "np.divide(a1, std, out=a1) # now a holds normalized values\n",
        "np.multiply(a1, 1.2, out=a1) # in-place scaling\n",
        "np.clip(a1, -1, 1, out=a1) # in-place clipping\n",
        "\n",
        "print(a1)\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "print(\"After:\", mem())\n",
        "print(\"Elapsed:\", t1 - t0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytUDbvYnIRdb",
        "outputId": "6b28d8b3-cd54-4c8a-f132-f89fc21f42c7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000000,) float32\n",
            "Before: 850.4609375\n",
            "[ 0.59612584 -0.16583821  0.7772928  ...  1.          0.77335644\n",
            "  1.        ]\n",
            "After: 850.4609375\n",
            "Elapsed: 0.05406355857849121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#more optimised way\n",
        "import numpy as np\n",
        "import time, psutil, os\n",
        "\n",
        "process = psutil.Process(os.getpid())\n",
        "def mem(): return process.memory_info().rss / 1024**2\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "a2 = np.empty(N, dtype=np.float32)\n",
        "a2 = np.random.randn(10000000).astype(a2.dtype, copy=False)\n",
        "print(a2.shape,a2.dtype)\n",
        "\n",
        "print(\"Before:\", mem())\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "#normalize:\n",
        "mean = a2.mean()\n",
        "std = a2.std()\n",
        "\n",
        "a2 -= mean\n",
        "a2 /= std\n",
        "a2 *= 1.2\n",
        "np.clip(a2, -1, 1, out=a2)\n",
        "\n",
        "print(a2)\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "print(\"After:\", mem())\n",
        "print(\"Elapsed:\", t1 - t0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFp4HNZcLM0C",
        "outputId": "e3a44b26-827a-4d6c-d471-918a13899dab"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000000,) float32\n",
            "Before: 812.3125\n",
            "[ 0.59612584 -0.16583821  0.7772928  ...  1.          0.77335644\n",
            "  1.        ]\n",
            "After: 812.3125\n",
            "Elapsed: 0.054196834564208984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python loop vs list-comprehension vs NumPy vectorized: timing recipe and expected differences"
      ],
      "metadata": {
        "id": "sQBUt2WXSnsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "N = 10000000\n",
        "\n",
        "t01 = time.time()\n",
        "#Python loop\n",
        "y1 = []\n",
        "for xi in range(N):\n",
        "    y1.append(2*xi + 3)\n",
        "\n",
        "t11 = time.time()\n",
        "print(f\"elapsed 1: {t11-t01}\")\n",
        "\n",
        "t02 = time.time()\n",
        "#list-comprehension\n",
        "y2 = [2*xi + 3 for xi in range(N)]\n",
        "\n",
        "t12 = time.time()\n",
        "print(f\"elapsed 2: {t12-t02}\")\n",
        "\n",
        "t03 = time.time()\n",
        "#NumPy vectorized\n",
        "y3 = 2*np.arange(N) + 3\n",
        "\n",
        "t13 = time.time()\n",
        "print(f\"elapsed 3: {t13-t03}\")\n",
        "\n",
        "print(y1==y2==y3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CX_X_8zkOu9G",
        "outputId": "9921d10b-4a0e-41c5-df7e-b58967674fec"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapsed 1: 1.5675709247589111\n",
            "elapsed 2: 1.0534443855285645\n",
            "elapsed 3: 0.041155099868774414\n",
            "[ True  True  True ...  True  True  True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Expected results (order of magnitude)\n",
        "\n",
        "- Python loop (pure for) is typically much slower because every element touched by Python interpreter: expect multiple orders of magnitude slower for large N.\n",
        "\n",
        "- List comprehension is faster than for loop because it’s implemented in C loops for list construction, but still elementwise Python arithmetic overhead exists.\n",
        "\n",
        "- NumPy vectorized operations (2 * x + 3) will usually be 10× to 100× (or more) faster than list comprehension for large arrays, depending on hardware, dtype, and operation complexity. For heavy BLAS-backed operations (matrix multiply) speedups can be even larger because highly optimized multi-threaded BLAS is used."
      ],
      "metadata": {
        "id": "fSI73F3-T93H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create a random RGB image\n",
        "img = np.random.rand(5,3).astype(np.float32)\n",
        "\n",
        "print(img.shape)  # (128, 128, 3)\n",
        "print(img.dtype)  # uint8\n",
        "\n",
        "U, S, VT = np.linalg.svd(img, full_matrices=False)\n",
        "print(U.shape,S.shape,VT.shape)\n",
        "\n",
        "k = 3\n",
        "\n",
        "S_k = np.diag(S[:k])\n",
        "U_k = U[:, :k]\n",
        "VT_k = VT[:k, :]\n",
        "\n",
        "print(S_k.shape,U_k.shape,VT_k.shape)\n",
        "\n",
        "img_approx = U_k @ S_k @ VT_k\n",
        "print(img_approx.shape)\n",
        "\n",
        "img_centered = img - np.mean(img, axis=0)\n",
        "\n",
        "# 2. Covariance\n",
        "cov = np.cov(img_centered, rowvar=False) # rowvar=False -> columns are features\n",
        "\n",
        "# 3. Eigen decomposition\n",
        "eigvals, eigvecs = np.linalg.eigh(cov)  # use eigh because cov is symmetric\n",
        "\n",
        "# 4. Sort eigenvectors by decreasing eigenvalues\n",
        "idx = np.argsort(eigvals)[::-1]\n",
        "eigvals = eigvals[idx]\n",
        "eigvecs = eigvecs[:, idx]\n",
        "\n",
        "print(eigvals, eigvecs)\n",
        "\n",
        "# 5. Project\n",
        "img_proj = img_centered @ eigvecs[:, :k]\n",
        "print(img_proj)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkvAFYZxS1Eh",
        "outputId": "a91d907a-46c5-4228-c447-bf79b2b0b146"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 3)\n",
            "float32\n",
            "(5, 3) (3,) (3, 3)\n",
            "(3, 3) (5, 3) (3, 3)\n",
            "(5, 3)\n",
            "[0.126599   0.05859047 0.00599779] [[-0.7376957  -0.66101127 -0.13736504]\n",
            " [-0.6100853   0.56553883  0.55494302]\n",
            " [ 0.28913833 -0.49318347  0.82046882]]\n",
            "[[ 0.10524312 -0.30412869  0.03588952]\n",
            " [-0.3592992  -0.09077504  0.0629198 ]\n",
            " [ 0.55346905  0.13309621  0.02377278]\n",
            " [-0.23651631  0.33294493  0.011736  ]\n",
            " [-0.06289676 -0.07113769 -0.13431798]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Example system\n",
        "A = np.array([[2, 1],\n",
        "              [1, 3]])\n",
        "b = np.array([8, 13])\n",
        "\n",
        "# Solve square system\n",
        "x = np.linalg.solve(A, b)\n",
        "print(\"Solution (solve):\", x)\n",
        "\n",
        "# Overdetermined system\n",
        "A2 = np.array([[1, 1],\n",
        "               [1, 2],\n",
        "               [1, 3]])\n",
        "b2 = np.array([6, 0, 0])\n",
        "x_ls, residuals, rank, s = np.linalg.lstsq(A2, b2, rcond=None)\n",
        "print(\"Solution (least squares):\", x_ls)\n",
        "print(\"Residuals:\", residuals)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdvanDUOfnBH",
        "outputId": "9414bbb7-3557-46d9-d002-f6d0cc09ac2e"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solution (solve): [2.2 3.6]\n",
            "Solution (least squares): [ 8. -3.]\n",
            "Residuals: [6.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_-cO0MLvfocI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}